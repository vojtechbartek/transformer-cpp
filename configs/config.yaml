batch_size: 2
vocab_size: 257
seq_len: 5
embedding_dim: 768
num_layers: 2
head_sizes: [128, 512]
ff_hidden_dims: [128, 1200]
layer_output_dims: [128]
num_epochs: 4
learning_rate: 0.00001
